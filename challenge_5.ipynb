{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbd5ad2",
   "metadata": {},
   "source": [
    "# Airport Weather Alerts with Gemini\n",
    "\n",
    "This notebook demonstrates the power of Gemini AI to generate intelligent weather alerts for airports. \n",
    "\n",
    "1. **Fetch real-time weather data** from the National Weather Service API for US airports\n",
    "2. **Store structured data** in BigQuery tables\n",
    "3. **Use Gemini 2.5 Flash** to analyze weather forecasts and generate actionable alerts\n",
    "4. **Extract insights** from unstructured weather data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f6b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the file\n",
    "df = pd.read_csv('gs://labs.roitraining.com/data-to-ai-workshop/airports.csv')\n",
    "\n",
    "# Pull the data schema and data types to determine the required table schema.\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ebd8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the file into a BigQuery table\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Set dataset reference vars.\n",
    "project_id = \"qwiklabs-gcp-02-949c0486d822\"\n",
    "dataset_id = \"dani_data_to_ai_workshop\"\n",
    "table_id = \"airports\"\n",
    "\n",
    "dataset_ref = bigquery.DatasetReference(project_id, dataset_id)\n",
    "dataset = bigquery.Dataset(dataset_ref)\n",
    "client.create_dataset(dataset, exists_ok=True)\n",
    "\n",
    "# Define the schema\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"id\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"ident\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"type\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"name\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"latitude_deg\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"longitude_deg\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"elevation_ft\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"continent\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"iso_country\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"iso_region\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"municipality\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"scheduled_service\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"icao_code\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"iata_code\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"gps_code\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"local_code\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"home_link\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"wikipedia_link\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"keywords\", \"STRING\"),\n",
    "]\n",
    "\n",
    "# Create the table if it doesn't exist.\n",
    "table_ref = bigquery.TableReference(dataset_ref, table_id)\n",
    "table = bigquery.Table(table_ref, schema=schema)\n",
    "client.create_table(table, exists_ok=True)\n",
    "\n",
    "# Load the data into the table.\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=schema,\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    "    skip_leading_rows=1,  # Skip the header row\n",
    ")\n",
    "\n",
    "job = client.load_table_from_uri(\n",
    "    'gs://labs.roitraining.com/data-to-ai-workshop/airports.csv',\n",
    "    table,\n",
    "    location='US',\n",
    "    job_config=job_config\n",
    ")\n",
    "\n",
    "try:\n",
    "    job.result()  # Wait for the job to complete\n",
    "    table = client.get_table(table_ref)\n",
    "    print(f\"Loaded {table.num_rows} rows and {len(table.schema)} columns to {table_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "\n",
    "\n",
    "# Validate the table was created.\n",
    "table = client.get_table(table_ref)\n",
    "print(f\"Table {table_id} created with {table.num_rows} rows and {len(table.schema)} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ae690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch weather forecasts for all large airports in the US using the National Weather Service API\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# First, let's query our BigQuery table to get all large airports in the US\n",
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Query to get all large airports in the US\n",
    "query = f\"\"\"\n",
    "SELECT id, ident, name, latitude_deg, longitude_deg, municipality\n",
    "FROM `{project_id}.{dataset_id}.airports`\n",
    "WHERE iso_country = 'US' \n",
    "AND type = 'large_airport'\n",
    "\"\"\"\n",
    "\n",
    "# Run the query\n",
    "query_job = client.query(query)\n",
    "results = query_job.result()\n",
    "\n",
    "# Convert to DataFrame\n",
    "large_airports_df = pd.DataFrame(\n",
    "    [(row.id, row.ident, row.name, row.latitude_deg, row.longitude_deg, row.municipality) \n",
    "     for row in results],\n",
    "    columns=['id', 'ident', 'name', 'latitude_deg', 'longitude_deg', 'municipality']\n",
    ")\n",
    "\n",
    "print(f\"Found {len(large_airports_df)} large airports in the US\")\n",
    "print(large_airports_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a9b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get weather forecast from NWS API\n",
    "def get_weather_forecast(lat, lon):\n",
    "    \"\"\"\n",
    "    Get weather forecast from the National Weather Service API for a specific latitude/longitude\n",
    "    \"\"\"\n",
    "    # Step 1: Get the grid endpoint for the location\n",
    "    points_url = f\"https://api.weather.gov/points/{lat},{lon}\"\n",
    "    \n",
    "    # Set headers for API request (NWS API requires a user agent)\n",
    "    headers = {\n",
    "        'User-Agent': 'BigQuery Weather Integration (dpalencia@burwood.com)',\n",
    "        'Accept': 'application/geo+json'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Get the points data\n",
    "        points_response = requests.get(points_url, headers=headers)\n",
    "        points_response.raise_for_status()  # Raise exception for HTTP errors\n",
    "        points_data = points_response.json()\n",
    "        \n",
    "        # Extract the forecast URL\n",
    "        forecast_url = points_data['properties']['forecast']\n",
    "        \n",
    "        # Get the forecast data\n",
    "        forecast_response = requests.get(forecast_url, headers=headers)\n",
    "        forecast_response.raise_for_status()\n",
    "        forecast_data = forecast_response.json()\n",
    "        \n",
    "        # Return the forecast periods\n",
    "        return forecast_data['properties']['periods']\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching forecast: {e}\")\n",
    "        return None\n",
    "    except (KeyError, ValueError) as e:\n",
    "        print(f\"Error parsing forecast data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to process forecast data into a structured format\n",
    "def process_forecast(forecast_periods, airport_id, airport_name):\n",
    "    \"\"\"\n",
    "    Process forecast periods into a structured format for BigQuery\n",
    "    \"\"\"\n",
    "    if not forecast_periods:\n",
    "        return []\n",
    "    \n",
    "    processed_forecasts = []\n",
    "    \n",
    "    for period in forecast_periods:\n",
    "        forecast_entry = {\n",
    "            'airport_id': airport_id,\n",
    "            'airport_name': airport_name,\n",
    "            'forecast_time': datetime.now().isoformat(),\n",
    "            'period_name': period.get('name', ''),\n",
    "            'period_start': period.get('startTime', ''),\n",
    "            'period_end': period.get('endTime', ''),\n",
    "            'temperature': period.get('temperature', None),\n",
    "            'temperature_unit': period.get('temperatureUnit', ''),\n",
    "            'wind_speed': period.get('windSpeed', ''),\n",
    "            'wind_direction': period.get('windDirection', ''),\n",
    "            'short_forecast': period.get('shortForecast', ''),\n",
    "            'detailed_forecast': period.get('detailedForecast', '')\n",
    "        }\n",
    "        processed_forecasts.append(forecast_entry)\n",
    "    \n",
    "    return processed_forecasts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef18741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch weather forecasts for all large airports\n",
    "all_forecasts = []\n",
    "\n",
    "# Add a rate limiter to respect the API's limits\n",
    "for index, airport in large_airports_df.iterrows():\n",
    "    print(f\"Fetching forecast for {airport['name']} ({airport['ident']})\")\n",
    "    \n",
    "    # Get the forecast\n",
    "    forecast_periods = get_weather_forecast(airport['latitude_deg'], airport['longitude_deg'])\n",
    "    \n",
    "    # Process the forecast if we got data\n",
    "    if forecast_periods:\n",
    "        processed_forecasts = process_forecast(forecast_periods, airport['id'], airport['name'])\n",
    "        all_forecasts.extend(processed_forecasts)\n",
    "        print(f\"  Got {len(processed_forecasts)} forecast periods\")\n",
    "    else:\n",
    "        print(f\"  No forecast data available\")\n",
    "    \n",
    "    # Sleep to respect rate limits\n",
    "    time.sleep(1.5)  # Sleep for 1.5 seconds between requests\n",
    "\n",
    "# Convert all forecasts to a DataFrame\n",
    "forecasts_df = pd.DataFrame(all_forecasts)\n",
    "\n",
    "print(f\"\\nCollected {len(forecasts_df)} forecast periods for {len(large_airports_df)} airports\")\n",
    "print(forecasts_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526c9841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BigQuery table for the weather forecasts\n",
    "\n",
    "# Define the schema for the airport_weather_forecasts table\n",
    "forecast_schema = [\n",
    "    bigquery.SchemaField(\"airport_id\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"airport_name\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"forecast_time\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"period_name\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"period_start\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"period_end\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"temperature\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"temperature_unit\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"wind_speed\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"wind_direction\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"short_forecast\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"detailed_forecast\", \"STRING\"),\n",
    "]\n",
    "\n",
    "# Create a new table for the forecasts\n",
    "forecast_table_id = \"airport_weather_forecasts\"\n",
    "forecast_table_ref = bigquery.TableReference(dataset_ref, forecast_table_id)\n",
    "forecast_table = bigquery.Table(forecast_table_ref, schema=forecast_schema)\n",
    "\n",
    "# Create the table (or replace if it exists)\n",
    "client.create_table(forecast_table, exists_ok=True)\n",
    "print(f\"Created table {project_id}.{dataset_id}.{forecast_table_id}\")\n",
    "\n",
    "# Convert DataFrame to format suitable for BigQuery\n",
    "# Keep the datetime columns as strings to match the schema\n",
    "# No conversion needed as they should already be strings\n",
    "\n",
    "# Load the data into BigQuery\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=forecast_schema,\n",
    "    write_disposition=\"WRITE_TRUNCATE\",  # Replace any existing data\n",
    ")\n",
    "\n",
    "job = client.load_table_from_dataframe(\n",
    "    forecasts_df, \n",
    "    forecast_table_ref,\n",
    "    job_config=job_config,\n",
    "    location=\"US\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    job.result()  # Wait for the job to complete\n",
    "    forecast_table = client.get_table(forecast_table_ref)\n",
    "    print(f\"Loaded {forecast_table.num_rows} rows and {len(forecast_table.schema)} columns to {forecast_table_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "\n",
    "# Validate the table was created successfully\n",
    "forecast_table = client.get_table(forecast_table_ref)\n",
    "print(f\"Table {forecast_table_id} created with {forecast_table.num_rows} rows and {len(forecast_table.schema)} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe85e687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the data to verify it was loaded correctly\n",
    "\n",
    "# Sample query to get the latest forecasts for each airport\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    airport_name,\n",
    "    period_name,\n",
    "    temperature,\n",
    "    temperature_unit,\n",
    "    wind_speed,\n",
    "    wind_direction,\n",
    "    short_forecast\n",
    "FROM \n",
    "    `{project_id}.{dataset_id}.{forecast_table_id}`\n",
    "ORDER BY \n",
    "    airport_name,\n",
    "    period_start\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "# Run the query\n",
    "query_job = client.query(query)\n",
    "results = query_job.result()\n",
    "\n",
    "# Display the results\n",
    "print(\"Sample of weather forecast data:\")\n",
    "for row in results:\n",
    "    print(f\"{row.airport_name} - {row.period_name}: {row.temperature}°{row.temperature_unit}, {row.wind_speed} {row.wind_direction}, {row.short_forecast}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c36a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gemini model in BigQuery using REMOTE WITH CONNECTION\n",
    "\n",
    "# Set the connection name for Vertex AI\n",
    "connection_name = \"us-central1.vertex-ai\"\n",
    "\n",
    "# SQL query to create a Gemini model using REMOTE WITH CONNECTION\n",
    "create_model_query = f\"\"\"\n",
    "CREATE OR REPLACE MODEL `{project_id}.{dataset_id}.airport_gemini_model`\n",
    "REMOTE WITH CONNECTION `{project_id}.{connection_name}`\n",
    "OPTIONS (\n",
    "  endpoint = 'gemini-2.5-flash'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Execute the CREATE MODEL query\n",
    "try:\n",
    "    job = client.query(create_model_query, location=\"US\")\n",
    "    job.result()  # Wait for the model to be created\n",
    "    print(f\"Successfully created model: {project_id}.{dataset_id}.airport_gemini_model\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Gemini model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd58142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate airport weather alerts using Gemini\n",
    "\n",
    "# First, let's create a query that joins airport data with weather forecasts\n",
    "# and prepares prompts for Gemini to generate alerts\n",
    "alert_query = f\"\"\"\n",
    "WITH airport_forecasts AS (\n",
    "  SELECT\n",
    "    a.id AS airport_id,\n",
    "    a.name AS airport_name,\n",
    "    a.municipality,\n",
    "    a.iso_region,\n",
    "    f.period_name,\n",
    "    f.temperature,\n",
    "    f.temperature_unit,\n",
    "    f.wind_speed,\n",
    "    f.wind_direction,\n",
    "    f.short_forecast,\n",
    "    f.detailed_forecast\n",
    "  FROM\n",
    "    `{project_id}.{dataset_id}.airports` a\n",
    "  JOIN\n",
    "    `{project_id}.{dataset_id}.{forecast_table_id}` f\n",
    "  ON\n",
    "    a.id = f.airport_id\n",
    "  WHERE\n",
    "    a.iso_country = 'US'\n",
    "    AND a.type = 'large_airport'\n",
    "  ORDER BY\n",
    "    a.name, f.period_start\n",
    "),\n",
    "airport_forecast_prompts AS (\n",
    "  SELECT\n",
    "    airport_id,\n",
    "    airport_name,\n",
    "    municipality,\n",
    "    iso_region,\n",
    "    CONCAT(\n",
    "      'Based on the following weather forecast for ', airport_name, ' in ', municipality, ', ',\n",
    "      STRING_AGG(\n",
    "        CONCAT(\n",
    "          period_name, ': ', temperature, '°', temperature_unit,\n",
    "          ', wind ', wind_speed, ' ', wind_direction,\n",
    "          ', ', short_forecast\n",
    "        ),\n",
    "        '. '\n",
    "      ),\n",
    "      '. Generate a concise list of potential weather alerts, warnings, or hazardous conditions that travelers should be aware of. ',\n",
    "      'Include severity levels (Low/Medium/High) and recommended precautions. ',\n",
    "      'Format the response as a structured list with bullet points for each alert. ',\n",
    "      'If there are no significant alerts, state that conditions appear normal.'\n",
    "    ) AS alert_prompt\n",
    "  FROM\n",
    "    airport_forecasts\n",
    "  GROUP BY\n",
    "    airport_id, airport_name, municipality, iso_region\n",
    "  LIMIT 10  -- Limiting to 10 airports for testing, remove this for production\n",
    ")\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  airport_forecast_prompts\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query to get the prompts\n",
    "alert_job = client.query(alert_query, location=\"US\")\n",
    "alert_results = alert_job.result()\n",
    "\n",
    "# Convert to a DataFrame\n",
    "alert_prompts_df = pd.DataFrame(\n",
    "    [(row.airport_id, row.airport_name, row.municipality, row.iso_region, row.alert_prompt) \n",
    "     for row in alert_results],\n",
    "    columns=['airport_id', 'airport_name', 'municipality', 'iso_region', 'alert_prompt']\n",
    ")\n",
    "\n",
    "print(f\"Generated prompts for {len(alert_prompts_df)} airports\")\n",
    "\n",
    "# Sample a prompt to see what it looks like\n",
    "if not alert_prompts_df.empty:\n",
    "    sample_row = alert_prompts_df.iloc[0]\n",
    "    print(\"\\n=== SAMPLE PROMPT ===\")\n",
    "    print(f\"Airport: {sample_row.airport_name}, Location: {sample_row.municipality}, {sample_row.iso_region}\")\n",
    "    print(\"\\nPrompt (truncated):\")\n",
    "    print(sample_row.alert_prompt[:500] + \"...\" if len(sample_row.alert_prompt) > 500 else sample_row.alert_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3029cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Gemini to generate alerts for each airport\n",
    "\n",
    "# Create a new table for airport alerts\n",
    "alerts_table_id = \"airport_weather_alerts\"\n",
    "\n",
    "# First, check if the alerts table already exists and delete it if it does\n",
    "alerts_table_ref = bigquery.TableReference(dataset_ref, alerts_table_id)\n",
    "\n",
    "try:\n",
    "    client.get_table(alerts_table_ref)\n",
    "    client.delete_table(alerts_table_ref)\n",
    "    print(f\"Deleted existing {alerts_table_id} table\")\n",
    "except Exception:\n",
    "    print(f\"Table {alerts_table_id} does not exist yet, will create it\")\n",
    "\n",
    "# Create the alerts table with ML.GENERATE_TEXT in the query\n",
    "alerts_query = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{project_id}.{dataset_id}.{alerts_table_id}` AS\n",
    "WITH airport_forecast_prompts AS (\n",
    "  SELECT\n",
    "    a.id AS airport_id,\n",
    "    a.name AS airport_name,\n",
    "    a.municipality,\n",
    "    a.iso_region,\n",
    "    CONCAT(\n",
    "      'Based on the following weather forecast for ', a.name, ' in ', a.municipality, ', ',\n",
    "      STRING_AGG(\n",
    "        CONCAT(\n",
    "          f.period_name, ': ', f.temperature, '°', f.temperature_unit,\n",
    "          ', wind ', f.wind_speed, ' ', f.wind_direction,\n",
    "          ', ', f.short_forecast\n",
    "        ),\n",
    "        '. '\n",
    "      ),\n",
    "      '. Generate a concise list of potential weather alerts, warnings, or hazardous conditions that travelers should be aware of. ',\n",
    "      'Make the response concise; only a few sentences. ',\n",
    "      'If there are no significant alerts, state that conditions appear normal.'\n",
    "    ) AS alert_prompt\n",
    "  FROM\n",
    "    `{project_id}.{dataset_id}.airports` a\n",
    "  JOIN\n",
    "    `{project_id}.{dataset_id}.{forecast_table_id}` f\n",
    "  ON\n",
    "    a.id = f.airport_id\n",
    "  WHERE\n",
    "    a.iso_country = 'US'\n",
    "    AND a.type = 'large_airport'\n",
    "  GROUP BY\n",
    "    a.id, a.name, a.municipality, a.iso_region\n",
    "  LIMIT 10  -- Limiting to 10 airports for testing, remove this for production\n",
    ")\n",
    "SELECT\n",
    "  p.airport_id,\n",
    "  p.airport_name,\n",
    "  p.municipality,\n",
    "  p.iso_region,\n",
    "  CURRENT_TIMESTAMP() AS generated_at,\n",
    "  p.alert_prompt,\n",
    "  (SELECT ml_generate_text_result FROM ML.GENERATE_TEXT(\n",
    "    MODEL `{project_id}.{dataset_id}.airport_gemini_model`,\n",
    "    (SELECT p.alert_prompt AS prompt),\n",
    "    STRUCT(0.2 AS temperature, 2048 AS max_output_tokens)\n",
    "  )) AS alert_response,\n",
    "  -- Extract text directly from the model response\n",
    "  JSON_VALUE((SELECT ml_generate_text_result FROM ML.GENERATE_TEXT(\n",
    "    MODEL `{project_id}.{dataset_id}.airport_gemini_model`,\n",
    "    (SELECT p.alert_prompt AS prompt),\n",
    "    STRUCT(0.2 AS temperature, 2048 AS max_output_tokens)\n",
    "  )), '$.candidates[0].content.parts[0].text') AS alert_text\n",
    "FROM\n",
    "  airport_forecast_prompts p\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query to create the alerts table\n",
    "try:\n",
    "    create_job = client.query(alerts_query, location=\"US\")\n",
    "    create_job.result()\n",
    "    print(\"Successfully created airport weather alerts table\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating alerts table: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ee372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the alerts table to verify the results\n",
    "\n",
    "# Sample query to get the alerts for each airport\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    airport_name,\n",
    "    municipality,\n",
    "    iso_region,\n",
    "    generated_at,\n",
    "    alert_text\n",
    "FROM \n",
    "    `{project_id}.{dataset_id}.{alerts_table_id}`\n",
    "ORDER BY \n",
    "    airport_name\n",
    "\"\"\"\n",
    "\n",
    "# Run the query\n",
    "query_job = client.query(query)\n",
    "results = query_job.result()\n",
    "\n",
    "# Display the results\n",
    "print(\"Airport Weather Alerts Generated by Gemini:\\n\")\n",
    "for row in results:\n",
    "    print(f\"=== {row.airport_name} ({row.municipality}, {row.iso_region}) ===\")\n",
    "    print(f\"Generated at: {row.generated_at}\")\n",
    "    print(\"\\nAlerts:\")\n",
    "    print(row.alert_text)\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
