{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46eef4ed",
   "metadata": {},
   "source": [
    "# Airport Weather Alerts with Gemini\n",
    "\n",
    "This notebook is the scheduled version of the Challenge 5 notebook, meant to run periodically. For this assignment it is set to run every 3 hours.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd63a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the file into a BigQuery table\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Set dataset reference vars.\n",
    "project_id = \"qwiklabs-gcp-02-949c0486d822\"\n",
    "dataset_id = \"dani_data_to_ai_workshop\"\n",
    "table_id = \"airports\"\n",
    "\n",
    "dataset_ref = bigquery.DatasetReference(project_id, dataset_id)\n",
    "dataset = bigquery.Dataset(dataset_ref)\n",
    "client.create_dataset(dataset, exists_ok=True)\n",
    "\n",
    "# Define the schema\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"id\", \"INTEGER\"),\n",
    "    bigquery.SchemaField(\"ident\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"type\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"name\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"latitude_deg\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"longitude_deg\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"elevation_ft\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"continent\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"iso_country\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"iso_region\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"municipality\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"scheduled_service\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"icao_code\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"iata_code\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"gps_code\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"local_code\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"home_link\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"wikipedia_link\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"keywords\", \"STRING\"),\n",
    "]\n",
    "\n",
    "# Create the table if it doesn't exist.\n",
    "table_ref = bigquery.TableReference(dataset_ref, table_id)\n",
    "table = bigquery.Table(table_ref, schema=schema)\n",
    "client.create_table(table, exists_ok=True)\n",
    "\n",
    "# Load the data into the table.\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=schema,\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    "    skip_leading_rows=1,  # Skip the header row\n",
    ")\n",
    "\n",
    "job = client.load_table_from_uri(\n",
    "    'gs://labs.roitraining.com/data-to-ai-workshop/airports.csv',\n",
    "    table,\n",
    "    location='US',\n",
    "    job_config=job_config\n",
    ")\n",
    "\n",
    "try:\n",
    "    job.result()  # Wait for the job to complete\n",
    "    table = client.get_table(table_ref)\n",
    "    print(f\"Loaded {table.num_rows} rows and {len(table.schema)} columns to {table_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "\n",
    "\n",
    "# Validate the table was created.\n",
    "table = client.get_table(table_ref)\n",
    "print(f\"Table {table_id} created with {table.num_rows} rows and {len(table.schema)} columns\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
